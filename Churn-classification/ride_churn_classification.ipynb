{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages and data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopy.distance\n",
    "df=pd.read_csv('rides.csv', parse_dates=['request_ts', 'accept_ts', 'pickup_ts', 'dropoff_ts', 'cancel_ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>request_ts</th>\n",
       "      <th>accept_ts</th>\n",
       "      <th>pickup_location</th>\n",
       "      <th>dropoff_location</th>\n",
       "      <th>pickup_ts</th>\n",
       "      <th>dropoff_ts</th>\n",
       "      <th>cancel_ts</th>\n",
       "      <th>status</th>\n",
       "      <th>statuscom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000023</td>\n",
       "      <td>106891</td>\n",
       "      <td>105286.0</td>\n",
       "      <td>2021-05-27 19:38:00</td>\n",
       "      <td>2021-05-27 19:40:00</td>\n",
       "      <td>40.6851859  -73.99472165</td>\n",
       "      <td>40.83142658 -73.91271123</td>\n",
       "      <td>2021-05-27 19:48:00</td>\n",
       "      <td>2021-05-27 21:10:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>completed</td>\n",
       "      <td>completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000024</td>\n",
       "      <td>116375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-12-05 00:02:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>40.81098464 -74.11502434</td>\n",
       "      <td>40.80982049 -73.80320195</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-12-05 00:15:00</td>\n",
       "      <td>requested</td>\n",
       "      <td>completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000025</td>\n",
       "      <td>104571</td>\n",
       "      <td>109087.0</td>\n",
       "      <td>2021-07-09 09:06:00</td>\n",
       "      <td>2021-07-09 09:16:00</td>\n",
       "      <td>40.84414807 -73.84599412</td>\n",
       "      <td>40.8662361  -73.97788948</td>\n",
       "      <td>2021-07-09 09:28:00</td>\n",
       "      <td>2021-07-09 09:55:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>completed</td>\n",
       "      <td>completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000026</td>\n",
       "      <td>109497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-19 17:03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>40.6581083  -73.90199317</td>\n",
       "      <td>40.7820038  -74.1057497</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-07-19 17:08:00</td>\n",
       "      <td>requested</td>\n",
       "      <td>completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000288</td>\n",
       "      <td>116687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-12-12 08:57:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>40.76639545 -73.877075</td>\n",
       "      <td>40.67157145 -73.88681784</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-12-12 09:05:00</td>\n",
       "      <td>requested</td>\n",
       "      <td>completed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ride_id  user_id  driver_id          request_ts           accept_ts  \\\n",
       "0  3000023   106891   105286.0 2021-05-27 19:38:00 2021-05-27 19:40:00   \n",
       "1  3000024   116375        NaN 2021-12-05 00:02:00                 NaT   \n",
       "2  3000025   104571   109087.0 2021-07-09 09:06:00 2021-07-09 09:16:00   \n",
       "3  3000026   109497        NaN 2021-07-19 17:03:00                 NaT   \n",
       "4  3000288   116687        NaN 2021-12-12 08:57:00                 NaT   \n",
       "\n",
       "            pickup_location          dropoff_location           pickup_ts  \\\n",
       "0  40.6851859  -73.99472165  40.83142658 -73.91271123 2021-05-27 19:48:00   \n",
       "1  40.81098464 -74.11502434  40.80982049 -73.80320195                 NaT   \n",
       "2  40.84414807 -73.84599412  40.8662361  -73.97788948 2021-07-09 09:28:00   \n",
       "3  40.6581083  -73.90199317   40.7820038  -74.1057497                 NaT   \n",
       "4    40.76639545 -73.877075  40.67157145 -73.88681784                 NaT   \n",
       "\n",
       "           dropoff_ts           cancel_ts     status  statuscom  \n",
       "0 2021-05-27 21:10:00                 NaT  completed  completed  \n",
       "1                 NaT 2021-12-05 00:15:00  requested  completed  \n",
       "2 2021-07-09 09:55:00                 NaT  completed  completed  \n",
       "3                 NaT 2021-07-19 17:08:00  requested  completed  \n",
       "4                 NaT 2021-12-12 09:05:00  requested  completed  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 385477 entries, 0 to 385476\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   ride_id           385477 non-null  int64         \n",
      " 1   user_id           385477 non-null  int64         \n",
      " 2   driver_id         248379 non-null  float64       \n",
      " 3   request_ts        385477 non-null  datetime64[ns]\n",
      " 4   accept_ts         248379 non-null  datetime64[ns]\n",
      " 5   pickup_location   385477 non-null  object        \n",
      " 6   dropoff_location  385477 non-null  object        \n",
      " 7   pickup_ts         223652 non-null  datetime64[ns]\n",
      " 8   dropoff_ts        223652 non-null  datetime64[ns]\n",
      " 9   cancel_ts         161825 non-null  datetime64[ns]\n",
      " 10  status            385477 non-null  object        \n",
      " 11  statuscom         385477 non-null  object        \n",
      "dtypes: datetime64[ns](5), float64(1), int64(2), object(4)\n",
      "memory usage: 35.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the target variable\n",
    "mask = df['accept_ts'].isna()\n",
    "df.loc[mask, 'accepted'] = 0\n",
    "df.loc[~mask, 'accepted'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split long and lat and convert to float\n",
    "df[['pickup_lat', 'pickup_long']]=df['pickup_location'].str.split(' -', expand=True).astype('float')\n",
    "df[['dropoff_lat', 'dropoff_long']]=df['dropoff_location'].str.split(' -', expand=True).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate distances\n",
    "distance = []\n",
    "for row in df.itertuples(index=False):\n",
    "    distance.append(geopy.distance.geodesic((row.pickup_lat, row.pickup_long),(row.dropoff_lat, row.dropoff_long)).km)\n",
    "df['distance']= distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract months, dow, hour from request time\n",
    "#try df['request_ts'].dt.month\n",
    "df['month'] = df['request_ts'].dt.month\n",
    "df['day_of_week'] = df['request_ts'].dt.day_of_week\n",
    "df['hour'] = df['request_ts'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unneeded columns, create X and y\n",
    "df_clean = df.drop(['driver_id', 'statuscom', 'pickup_ts', 'dropoff_ts', 'cancel_ts', 'accept_ts', 'status', 'pickup_location', 'dropoff_location', 'request_ts'], axis=1)\n",
    "y= df_clean['accepted']\n",
    "X= df_clean.loc[:, df_clean.columns != 'accepted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create holdout set grouping by user_id given that we have repeated observations, in order to avoid leakage\n",
    "from sklearn.model_selection import GroupShuffleSplit \n",
    "\n",
    "splitter = GroupShuffleSplit(test_size=.20, n_splits=1, random_state = 8)\n",
    "split = splitter.split(X, y, groups=X['user_id'])\n",
    "train_inds, test_inds= next(split)\n",
    "\n",
    "X_train = X.iloc[train_inds]\n",
    "X_test = X.iloc[test_inds]\n",
    "y_train = y.iloc[train_inds]\n",
    "y_test = y.iloc[test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a group filter for further splitting, drop user and ride id columns\n",
    "group = X_train['user_id']\n",
    "X_train = X_train.drop(columns=['ride_id', 'user_id'], axis=1)\n",
    "X_test= X_test.drop(columns=['ride_id', 'user_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(n_neighbors=30, weights='distance'))])\n",
      "{'knn__weights': 'distance', 'knn__n_neighbors': 30, 'knn__algorithm': 'auto'}\n",
      "0.6395640861436934\n"
     ]
    }
   ],
   "source": [
    "#knn model, takes several minutes to complete\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "knn = KNeighborsClassifier()\n",
    "scaler = MinMaxScaler()\n",
    "steps = [('scaler', scaler), ('knn', knn)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "param_distributions={'knn__n_neighbors':np.arange(3, 31), 'knn__weights':(['uniform', 'distance']), 'knn__algorithm':(['auto', 'ball_tree']) }\n",
    "cv= GroupShuffleSplit(test_size=0.2, n_splits=5, random_state=8)\n",
    "knn_cv = RandomizedSearchCV(estimator=pipeline, param_distributions=param_distributions, cv=cv, random_state=8,refit=True, n_jobs=-1)\n",
    "knn_cv.fit(X_train, y_train, groups=group) \n",
    "y_pred = knn_cv.predict(X_test)\n",
    "print(knn_cv.best_estimator_)\n",
    "print(knn_cv.best_params_)\n",
    "print(knn_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4309 23589]\n",
      " [ 4413 44985]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.15      0.24     27898\n",
      "         1.0       0.66      0.91      0.76     49398\n",
      "\n",
      "    accuracy                           0.64     77296\n",
      "   macro avg       0.58      0.53      0.50     77296\n",
      "weighted avg       0.60      0.64      0.57     77296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "from sklearn.metrics import  confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(criterion='log_loss', max_depth=6, min_samples_leaf=5,\n",
      "                       random_state=8)\n",
      "{'random_state': 8, 'min_samples_leaf': 5, 'max_depth': 6, 'criterion': 'log_loss'}\n",
      "0.6549000648156054\n",
      "[8.36296449e-03 2.08060697e-03 6.37792768e-03 3.09280768e-03\n",
      " 1.40852692e-02 9.63896273e-01 1.16860838e-03 9.35542618e-04]\n"
     ]
    }
   ],
   "source": [
    "#decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "cv= GroupShuffleSplit(test_size=0.2, n_splits=5, random_state=8)\n",
    "param_distributions={'max_depth':np.arange(3, 30), 'criterion':(['gini', 'entropy', 'log_loss']), 'random_state':[8], 'min_samples_leaf':np.arange(2, 10) }\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_cv = RandomizedSearchCV(estimator=dt, param_distributions=param_distributions, cv=cv, random_state=8,refit=True)\n",
    "dt_cv.fit(X_train, y_train, groups=group)\n",
    "y_pred = dt_cv.predict(X_test)\n",
    "print(dt_cv.best_estimator_)\n",
    "print(dt_cv.best_params_)\n",
    "print(dt_cv.best_score_)\n",
    "print(dt_cv.best_estimator_.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4524 23374]\n",
      " [ 3105 46293]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.16      0.25     27898\n",
      "         1.0       0.66      0.94      0.78     49398\n",
      "\n",
      "    accuracy                           0.66     77296\n",
      "   macro avg       0.63      0.55      0.52     77296\n",
      "weighted avg       0.64      0.66      0.59     77296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month\n",
       "1     0.720027\n",
       "2     0.617181\n",
       "3     0.444691\n",
       "4     0.434475\n",
       "5     0.508081\n",
       "6     0.571565\n",
       "7     0.615088\n",
       "8     0.650815\n",
       "9     0.671278\n",
       "10    0.702547\n",
       "11    0.714486\n",
       "12    0.732870\n",
       "Name: accepted, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percentage of accepted requests by month\n",
    "df.groupby('month')['accepted'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6390757607120678"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf= RandomForestClassifier(n_estimators=500, criterion= 'log_loss', max_depth=6,  random_state=8, bootstrap=False, min_samples_leaf=5, max_features='sqrt')\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0 27898]\n",
      " [    0 49398]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00     27898\n",
      "         1.0       0.64      1.00      0.78     49398\n",
      "\n",
      "    accuracy                           0.64     77296\n",
      "   macro avg       0.32      0.50      0.39     77296\n",
      "weighted avg       0.41      0.64      0.50     77296\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidecangemi/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/davidecangemi/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/davidecangemi/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
